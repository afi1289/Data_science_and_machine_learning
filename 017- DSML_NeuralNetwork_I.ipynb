{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Applications/Anaconda/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Applications/Anaconda/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Applications/Anaconda/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Applications/Anaconda/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# ich brauche immer 3 Teile in Keras\n",
    "from keras.models import Sequential # initial sequential NN \n",
    "from keras.layers import Dense      # hidden layer\n",
    "from keras.optimizers import SGD    # optimierer ist stochastic gradient descent\n",
    "import numpy as np\n",
    "import statsmodels.api as sm    # ich brauch das für OLS Schätzung\n",
    "from sklearn.metrics import mean_squared_error,log_loss # zur model Evalutaion nehme ich Mean squared error and log_loss (definiert als likelihood multinomial modell)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of some data\n",
    "np.random.seed (245)\n",
    "nobs =10000\n",
    "x1 = 2 * np.random.rand(nobs , 1)\n",
    "x2 = np.random.uniform(size=nobs).reshape((nobs ,1))\n",
    "y = -0.5 + 2 * x1 - 3*x2 + np.random.normal(loc=0, scale=1, size=nobs).reshape((nobs ,1)) # last one ist fehler term, weil ich OLS schätzen möchte\n",
    "X = np.c_[np.ones((nobs ,1)),x1,x2] #zusammenfassen zu einer Vektor\n",
    "OLS=sm.OLS(y,X).fit()\n",
    "y_pred_OLS=OLS.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.81370773, 0.77579057],\n",
       "       [1.        , 0.22506001, 0.28782192],\n",
       "       [1.        , 0.20060026, 0.4393781 ],\n",
       "       ...,\n",
       "       [1.        , 0.97487135, 0.30835699],\n",
       "       [1.        , 0.03773621, 0.19634294],\n",
       "       [1.        , 0.04727057, 0.42982725]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0:5] # erste Spalte in X immer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1677022 ],\n",
       "       [ 0.04029046],\n",
       "       [-1.12111839],\n",
       "       ...,\n",
       "       [ 0.85713025],\n",
       "       [-1.55088467],\n",
       "       [-1.5558517 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.673\n",
      "Model:                            OLS   Adj. R-squared:                  0.673\n",
      "Method:                 Least Squares   F-statistic:                 1.029e+04\n",
      "Date:                Thu, 05 Dec 2019   Prob (F-statistic):               0.00\n",
      "Time:                        13:40:45   Log-Likelihood:                -14241.\n",
      "No. Observations:               10000   AIC:                         2.849e+04\n",
      "Df Residuals:                    9997   BIC:                         2.851e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.5258      0.027    -19.784      0.000      -0.578      -0.474\n",
      "x1             2.0041      0.017    115.428      0.000       1.970       2.038\n",
      "x2            -2.9642      0.035    -84.838      0.000      -3.033      -2.896\n",
      "==============================================================================\n",
      "Omnibus:                        2.625   Durbin-Watson:                   1.987\n",
      "Prob(Omnibus):                  0.269   Jarque-Bera (JB):                2.647\n",
      "Skew:                          -0.020   Prob(JB):                        0.266\n",
      "Kurtosis:                       3.069   Cond. No.                         6.28\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters, die ich brauch für mein NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learningrate ist der zentralen Hyperparameter wichtige \n",
    "LR=0.05\n",
    "\n",
    "\n",
    "# Number of neurons-> hier gemient Output Neuron\n",
    "Neuron=1\n",
    "\n",
    "\n",
    "#The Activation function von output layer-> ich habe direkte Zusammenhang zwischen x und y -> hier habe keine Transofrmation (keine Sigmoid oder tanh-> a=z=W*x+b)\n",
    "Activate='linear'\n",
    "\n",
    "\n",
    "#The Optimizer stochastic gradient descent -> und gebe ich ihm der Learning rate\n",
    "Optimizer= SGD(lr=LR)\n",
    "\n",
    "\n",
    "# The loss function - Verlustfunktion ist schon definiert in keras\n",
    "loss='mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Neural Network\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed (245) # wichtig weil Anfang Gewichte in jedes mal gleich sein wird - NN hängt stark an Start von Zufalssgenertor -> welche Anfang Gewichte wird gewählt\n",
    "\n",
    "#Initialize the ANN - wichtig durch model_ANN zu initialisieren\n",
    "model_ANN= Sequential() # wir definieren unser NN - ich kann hier auch Layers direkt und Name übergeben! - implizit nur input Layer\n",
    "\n",
    "#Output Layer definieren zusätzliche Layer\n",
    "model_ANN.add(Dense(Neuron, activation=Activate, input_shape=(3,),use_bias=False)) # ein neuron, Aktivierungsfunktion='linear' look above! ,input_shape wie mein matrix X definiert ist, use_bias kein bias neuron\n",
    "model_ANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ich habe ein layer dense_1\n",
    "# ich habe shape\n",
    "# ich habe number of Parameter -> sind die Gewichte, die ich durch NN optimieren will!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ANN.compile(optimizer=Optimizer , loss=loss) # jetzt müssen wir NN kompilieren -> also in TensorFlow zu übersetze\n",
    "# optimierer ist stochastic gradient descent, and loss ist mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 2s 191us/step - loss: 1.2417\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0163\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0159\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0144\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0157\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0165\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 1.0163\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 1.0138\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 1.0149\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 1s 59us/step - loss: 1.0159\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 1s 54us/step - loss: 1.0166\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 1s 55us/step - loss: 1.0148\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 50us/step - loss: 1.0167\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 1s 58us/step - loss: 1.0154\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 1s 62us/step - loss: 1.0142\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 1s 50us/step - loss: 1.0160\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 1s 64us/step - loss: 1.0160\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 1.0161\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 1s 54us/step - loss: 1.0156\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 1s 54us/step - loss: 1.0151\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 1s 57us/step - loss: 1.0166\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 1s 50us/step - loss: 1.0147\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 1s 52us/step - loss: 1.0149\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 1.0151\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 1.0144\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0149\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 1s 53us/step - loss: 1.0151\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 1s 65us/step - loss: 1.0158\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 1.0135\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 1s 54us/step - loss: 1.0147\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 1s 59us/step - loss: 1.0142\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0162\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 1s 55us/step - loss: 1.0152\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 1.0147\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 1.0148\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 1s 55us/step - loss: 1.0151\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 1s 55us/step - loss: 1.0156\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 1.0150\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 1s 59us/step - loss: 1.0155\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 1s 53us/step - loss: 1.0150\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 1.0156\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 1.0159\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 1.0147\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0162\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0144\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 1.0162\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 1s 57us/step - loss: 1.0164\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 1.0164\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 1s 56us/step - loss: 1.0151\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 1s 57us/step - loss: 1.0159\n"
     ]
    }
   ],
   "source": [
    "#Fit the model - unsere NN traninieren -> \n",
    "history_ANN=model_ANN.fit(\n",
    "X, # training data\n",
    "y, # training targets\n",
    "epochs=50,verbose=1) # sage ich wie viele epochen (kann auch als Hyperparameter) -> \n",
    "# für jedes Gewicht machen wir 50 Update-Steps!, damit mein NN fertig trainiert bzw. auf Daten gelernt/angepasst)\n",
    "# -> dann schauen wir dass relativ nah an OLS (weil Aktivierungsfunktion Linear!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model loss die ich versuche zu minimieren \n",
    "plt.plot(history_ANN.history['loss'])\n",
    "#plt.plot(history_ANN.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# nach einem Step/Epoch kann mann sehen dass Loss realtiv gut minimiert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.52725685],\n",
       "        [ 1.971427  ],\n",
       "        [-2.964658  ]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# man kann sich dann Inforamtionen aus gfitten Layer ausgeben lassen\n",
    "model_ANN.layers[0]                # hier bekomme ich die Anzahl der Layers insgesamt    \n",
    "model_ANN.layers[0].get_weights()  # hier bekomme ich Gewichte, die Input-Layer mit Output-Layer verbinden! -> diese Gewicht sind nicht anders als Betas in OLS, weil mein NN wie OLS strukturiert hat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const [-0.52725685]\n",
      "Beta1 [1.971427]\n",
      "Beta1 [-2.964658]\n"
     ]
    }
   ],
   "source": [
    "#Estimated Weights \n",
    "print('const',model_ANN.layers[0]. get_weights ()[0][0])\n",
    "print('Beta1',model_ANN.layers[0]. get_weights ()[0][1])\n",
    "print('Beta1',model_ANN.layers[0]. get_weights ()[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52578554,  2.00410969, -2.96424973])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS.params # hier bekomme ich OLS Betas -> sind wie NN Gewichte, weil mein NN wie OLS strukturiert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE ANN: 1.011894178649231\n",
      "MSE OLS: 1.0103468380802312\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the fit\n",
    "y_pred_ANN=model_ANN.predict(X)\n",
    "print(\"MSE ANN:\", mean_squared_error(np.ravel(y), np.ravel(y_pred_ANN )))\n",
    "print(\"MSE OLS:\", mean_squared_error(np.ravel(y), np.ravel(y_pred_OLS )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate some data\n",
    "np.random.seed(245)\n",
    "nobs=10000\n",
    "mean = np.zeros(2)\n",
    "cov = np.eye(2)\n",
    "X=np.random.multivariate_normal(mean,cov,nobs)\n",
    "X=sm.add_constant(X)\n",
    "\n",
    "y_star= X.T[0]+ 5*X.T[1]+ 4*X.T[2] + np.random.logistic(size=nobs) # y*\n",
    "\n",
    "y=np.where(y_star>0,1,0) #wenn y* über Null dann y=1 sonst y=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.33539705, -2.14916892,  0.1318647 ,  5.88800974,  0.15844443])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_star[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5] # the first y* is 4.33539075 > 0 -> y = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.191293\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9997\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Thu, 05 Dec 2019   Pseudo R-squ.:                  0.7216\n",
      "Time:                        15:20:01   Log-Likelihood:                -1912.9\n",
      "converged:                       True   LL-Null:                       -6872.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9896      0.047     21.074      0.000       0.898       1.082\n",
      "x1             5.1413      0.129     39.769      0.000       4.888       5.395\n",
      "x2             4.2387      0.108     39.316      0.000       4.027       4.450\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.17 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "Logit_fit=sm.Logit(y, X).fit()\n",
    "print(Logit_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters - jetzt Netz an sich bleibt gleich aber ich brauche andere Aktivierungsfunktion, weil Logit model y=funktion(x*Beta) -> deswegen wird in dem Neuron sigmoid als Aktivierungsfunktion verwendet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learningrate\n",
    "LR=0.05\n",
    "\n",
    "\n",
    "# Number of neurons\n",
    "Neuron=1\n",
    "\n",
    "\n",
    "#The Activation function\n",
    "Activate='sigmoid' #aka logistic link -> ich bekomme zuerst Wahrschienlichkeit, diese Wahr. würde durch logistische Funktion(=sigmoid) zu 1 oder 0 transformiert!\n",
    "\n",
    "\n",
    "#The Optimizer\n",
    "Optimizer= SGD(lr=LR)\n",
    "\n",
    "\n",
    "# The loss function\n",
    "loss='binary_crossentropy' # aka binary_crossentropy ist nicht anders als negative log likelihood in the logit model-> wenn ich negative log likelihood minimiere dann maximiere ich im Endeffekt die Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Neural Network\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed (245)\n",
    "\n",
    "#Initialize the ANN\n",
    "model_Logit= Sequential()\n",
    "\n",
    "#Output Layer\n",
    "model_Logit.add(Dense(Neuron, activation=Activate, input_shape=(3,),use_bias=False))\n",
    "model_Logit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_Logit.compile(optimizer=Optimizer , loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 2s 221us/step - loss: 0.3692\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 1s 77us/step - loss: 0.2542\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 1s 77us/step - loss: 0.2297\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.2179\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.2109\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.2063\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 1s 86us/step - loss: 0.2031\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.2007\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.1990\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.1976\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.1966\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.1957\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.1950\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.1945\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.1940\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.1936\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.1933\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 1s 84us/step - loss: 0.1930\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.1928\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.1926\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 1s 86us/step - loss: 0.1924\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.1923\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.1922\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.1921\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.1920\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 1s 80us/step - loss: 0.1919\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.1918\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.1918\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.1918\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 1s 80us/step - loss: 0.1917\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 1s 80us/step - loss: 0.1917\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 1s 89us/step - loss: 0.1916\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.1916\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 1s 94us/step - loss: 0.1916\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.1916\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.1915\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.1915\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 1s 89us/step - loss: 0.1915\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.1915\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.1915\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.1915\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.1915\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 1s 93us/step - loss: 0.1914\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.1914\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.1914\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.1914\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.1914\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.1914\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.1914\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 0.1914\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "history_Logit=model_Logit.fit(\n",
    "X, # training data\n",
    "y, # training targets\n",
    "epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Logit.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.96776724],\n",
       "        [5.046778  ],\n",
       "        [4.170388  ]], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# man kann sich dann Inforamtionen aus gfitten Layer ausgeben lassen\n",
    "model_Logit.layers[0]                # hier bekomme ich die Anzahl der Layers insgesamt    \n",
    "model_Logit.layers[0].get_weights()  # hier bekomme ich Gewichte, die Input-Layer mit Output-Layer verbinden! -> diese Gewicht sind nicht anders als Betas in Logit, weil mein NN wie Logit strukturiert hat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const [0.96776724]\n",
      "Beta1 [5.046778]\n",
      "Beta1 [4.170388]\n"
     ]
    }
   ],
   "source": [
    "#Estimated Weights\n",
    "print('const',model_Logit.layers[0]. get_weights ()[0][0])\n",
    "print('Beta1',model_Logit.layers[0]. get_weights ()[0][1])\n",
    "print('Beta1',model_Logit.layers[0]. get_weights ()[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE ANN  : 0.19156017505611525\n",
      "MSE Logit: 0.19129313542069695\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the fit\n",
    "y_pred_ANN_Logit=model_Logit.predict_proba(X)\n",
    "y_pred_Logit=Logit_fit.predict(X)\n",
    "print(\"MSE ANN  :\", log_loss(np.ravel(y), np.ravel(y_pred_ANN_Logit),eps=0.001))\n",
    "print(\"MSE Logit:\", log_loss(np.ravel(y), np.ravel(y_pred_Logit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
