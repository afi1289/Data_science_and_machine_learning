{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jetzt machen wir genau gleiche x und y aber die Unterschied ist die Nützung andere Aktivierungsfunktionen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of some data\n",
    "np.random.seed (245)\n",
    "nobs =1000\n",
    "x1= np.random.normal(size=nobs ,scale=1) \n",
    "x2= np.random.normal(size=nobs ,scale=1)\n",
    "x3= np.random.normal(size=nobs ,scale=1)\n",
    "X= np.c_[np.ones((nobs ,1)),x1,x2,x3]\n",
    "\n",
    "\n",
    "y= -1.5 + -0.5*x1**2 -0.5*x2**2 +0.25*x3**2 + np.random.normal(size=nobs , scale=1)\n",
    "\n",
    "\n",
    "\n",
    "OLS=sm.OLS(y,X).fit()\n",
    "y_pred_OLS=OLS.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.23276742,  2.21909962, -1.00408117],\n",
       "       [ 1.        ,  0.81853041,  0.51334014,  0.86191678],\n",
       "       [ 1.        , -0.97334932, -3.00031139,  0.86598633],\n",
       "       ...,\n",
       "       [ 1.        ,  1.62168608, -0.91076001, -0.60039352],\n",
       "       [ 1.        , -0.18710805,  0.74539444, -0.31463947],\n",
       "       [ 1.        , -1.39579166, -1.03862314,  0.32594296]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.14038861, -1.56918942, -5.63452662, -1.37463074, -1.13933778])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,  14.,  34., 100., 212., 281., 256.,  81.,  15.,   4.]),\n",
       " array([-7.86412286, -6.83753031, -5.81093776, -4.78434521, -3.75775266,\n",
       "        -2.73116011, -1.70456756, -0.67797501,  0.34861754,  1.3752101 ,\n",
       "         2.40180265]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.208\n",
      "Date:                Thu, 05 Dec 2019   Prob (F-statistic):              0.306\n",
      "Time:                        21:14:32   Log-Likelihood:                -1776.1\n",
      "No. Observations:                1000   AIC:                             3560.\n",
      "Df Residuals:                     996   BIC:                             3580.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.3196      0.045    -51.122      0.000      -2.409      -2.231\n",
      "x1             0.0403      0.044      0.923      0.356      -0.045       0.126\n",
      "x2            -0.0181      0.045     -0.404      0.687      -0.106       0.070\n",
      "x3             0.0728      0.046      1.600      0.110      -0.016       0.162\n",
      "==============================================================================\n",
      "Omnibus:                       30.791   Durbin-Watson:                   2.082\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.067\n",
      "Skew:                          -0.380   Prob(JB):                     2.43e-08\n",
      "Kurtosis:                       3.513   Cond. No.                         1.09\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters\n",
    "### ich habe nicht gleiche Aktivierungsfunktion für alle meiner Neuronen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learningrate\n",
    "LR=0.05\n",
    "\n",
    "\n",
    "# Number of neurons\n",
    "Neuron_Out=1\n",
    "Neuron_Hidden=50\n",
    "\n",
    "#The Activation function\n",
    "Activate_output='linear' # für letzte Schicht verwende ich linear\n",
    "Activate_hidden='sigmoid' # unterschied ist Hidden-Layer-Neuronen werden nicht linear transformiert\n",
    "\n",
    "\n",
    "#The Optimizer\n",
    "Optimizer= SGD(lr=LR)\n",
    "\n",
    "\n",
    "# The loss function\n",
    "loss='mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 50        \n",
      "=================================================================\n",
      "Total params: 250\n",
      "Trainable params: 250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Neural Network\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed (245)\n",
    "\n",
    "#Initialize the ANN\n",
    "model_ANN= Sequential()\n",
    "\n",
    "# Hidden Layer\n",
    "model_ANN.add(Dense(Neuron_Hidden, activation=Activate_hidden, input_shape=(4,), use_bias=False))\n",
    "\n",
    "#Output Layer\n",
    "model_ANN.add(Dense(Neuron_Out, activation=Activate_output,use_bias=False))\n",
    "model_ANN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ANN.compile(optimizer=Optimizer , loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3629\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 2.1943\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.2333\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.2526\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.1445\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.1055\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.1399\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 2.0913\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.1177\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 2.1032\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1004\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.1751\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1510\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1154\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.1919\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1266\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1723\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 2.1702\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.0635\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1327\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.1123\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 2.1219\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.1621\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 2.1492\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 2.1538\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 2.1278\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 2.1533\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 2.1145\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.0697\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.0674\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.1056\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.0554\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.0382\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 2.0364\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.9864\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.9455\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.9561\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 2.0115\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.8938\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.8341\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 1.8384\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.8475\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.7379\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 1.7137\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 1.6959\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 1.6141\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 1.6173\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 1.5468\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 1.5286\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.4569\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.4822\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.4139\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.3898\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 1.3715\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 1.3584\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 1.3377\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 1.3257\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.3010\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.2644\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.3185\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 1.2653\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 1.2798\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.3138\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 1.2936\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.2524\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 1.2568\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.2446\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.2333\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 1.2522\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 1.2307\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 1.2393\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1.3023\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.2177\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1.2309\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 1.2564\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.2411\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.2465\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.2327\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 1.2380\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.2339\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 1.2446\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.2222\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.2391\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.1904\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 1.2205\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.2176\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.1911\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.1982\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.2173\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.2271\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.2219\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.2003\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.2016\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.2123\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.2153\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.2545\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.2271\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.1912\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.1836\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.1853\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.2247\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.1799\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.1886\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.2134\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 1.2099\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 1.1894\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.1813\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.1819\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.1739\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.1546\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.1616\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.1547\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.1822\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 1.1557\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 1.1392\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.1622\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.1490\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.1621\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 1.1273\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 1.1662\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.1522\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 1.1521\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.1241\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 1.1248\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 1.1270\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.1282\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.1363\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 1.1355\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 1.1724\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 1.1372\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.0998\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.1227\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.1534\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1.1064\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.1182\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 1.1249\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 1.1199\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.0910\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 1.0869\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 1.1144\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 1.0933\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 1.0909\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 1.0805\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 1.0569\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 1.0752\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 1.0805\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 1.0862\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.0735\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.1070\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0924\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0737\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.0659\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0608\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 1.0966\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1.1000\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 1.0719\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 1.0683\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 1.0761\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.0642\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.0544\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.0672\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0787\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.0823\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 1.0523\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.0879\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0706\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 1.0735\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 1.0551\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1.0848\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.0829\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0788\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0709\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0710\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.1245\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0621\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0541\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 1.1018\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.0650\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.0648\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0909\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.0446\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0580\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0662\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0625\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0579\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0562\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0539\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0638\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0602\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0443\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0613\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0730\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0514\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0804\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.0561\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0607\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0537\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0597\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0458\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0456\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.0633\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0627\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0486\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0421\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0520\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0450\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0420\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0756\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0420\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0807\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0518\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0680\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.0413\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0408\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0471\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0323\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0565\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0296\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0443\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0330\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0419\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0723\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0421\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0467\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0771\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0620\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0488\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0443\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0704\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0545\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0328\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.0540\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0374\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0381\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0460\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0413\n",
      "Epoch 237/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0435\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0489\n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0473\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0770\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0342\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0384\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0405\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0558\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0375\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0383\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0255\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0320\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0525\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0408\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.0228\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0412\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0519\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0409\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0364\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0627\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0365\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0157\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.0754\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0596\n",
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0251\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0313\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0357\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0213\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0446\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0708\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0393\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0400\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.0438\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0436\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.0336\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0464\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0434\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0261\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0323\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0350\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0297\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0270\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0231\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0277\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0586\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0552\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0290\n",
      "Epoch 284/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0254\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0353\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0418\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.0474\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0490\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0290\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0421\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0335\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0273\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0180\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0294\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0345\n",
      "Epoch 296/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0422\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0333\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0327\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0379\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0334\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0497\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0260\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0215\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0231\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0351\n",
      "Epoch 306/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0563\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0348\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0377\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0285\n",
      "Epoch 310/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0429\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0362\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0314\n",
      "Epoch 313/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0333\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0334\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0123\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0224\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0225\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0298\n",
      "Epoch 319/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0257\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0479\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.0287\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0246\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0255\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.0414\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0244\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0289\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0219\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0310\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0353\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0303\n",
      "Epoch 331/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.0487\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0620\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0266\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0181\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0220\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0404\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0392\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0193\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0151\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0186\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0366\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.0315\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0346\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.0336\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0250\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0339\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0356\n",
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.0509\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0056\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0117\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0242\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0257\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0253\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0358\n",
      "Epoch 355/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0156\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0299\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0163\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.0285\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0247\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.0256\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0150\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0390\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0457\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0271\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0178\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0330\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0218\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0333\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.0148\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0077\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0285\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0178\n",
      "Epoch 373/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0309\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.0213\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0219\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0250\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0207\n",
      "Epoch 378/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.0169\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0263\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0323\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0258\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0183\n",
      "Epoch 383/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0321\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0083\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0087\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0302\n",
      "Epoch 387/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0282\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0165\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0141\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.0177\n",
      "Epoch 391/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0246\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0143\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0338\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0188\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0137\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0290\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.0301\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0173\n",
      "Epoch 399/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0167\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0200\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0076\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0300\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0275\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0068\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0269\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0164\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0088\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0147\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0267\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0149\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0114\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0211\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0087\n",
      "Epoch 414/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0232\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.0032\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0140\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0339\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.0228\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0000\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0173\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0146\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0077\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0003\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0082\n",
      "Epoch 425/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0216\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0004\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.9975\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0072\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0059\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0192\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0169\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0341\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0111\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.0081\n",
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0164\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0149\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.9981\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0171\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0205\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0095\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.0171\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0008\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.9992\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.0108\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0117\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.9983\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0083\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0232\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0070\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.9996\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0057\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.0045\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0080\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0094\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0214\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.0056\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0094\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0006\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.0091\n",
      "Epoch 460/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0085\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0176\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0165\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0196\n",
      "Epoch 464/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0210\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0234\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0041\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.9913\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0047\n",
      "Epoch 469/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0055\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.0040\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0006\n",
      "Epoch 472/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0052\n",
      "Epoch 473/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0062\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0072\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0147\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0089\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0034\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0234\n",
      "Epoch 479/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0089\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0048\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.9947\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0328\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.0041\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0085\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.0064\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0114\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0005\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0081\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.9990\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0094\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.9957\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 1.0054\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0009\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0058\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.0201\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.0070\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.9988\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.0077\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.9911\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.9985\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "history_ANN=model_ANN.fit(\n",
    "X, # training data\n",
    "y, # training targets\n",
    "epochs=500,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_ANN.history['loss'])\n",
    "#plt.plot(history_ANN.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting the constant to 50 Neurons in the Hidden layer \n",
      "\n",
      " [ 1.0348754  -0.42895576 -0.5878439   0.08490722 -0.6848453  -0.91700923\n",
      " -0.52992624 -0.65447056 -2.8922071  -0.56118155 -0.3466174  -0.2431663\n",
      " -0.73255014 -0.9720989  -0.75777054 -0.46912488 -0.5824501  -1.4285849\n",
      " -0.08804358 -1.6935909  -1.3880444  -1.9185476  -0.63018805 -0.82501686\n",
      " -1.1104614  -0.9214852  -3.9199994  -3.2942708  -0.8316097  -0.6471592\n",
      " -0.42505115 -0.240991   -0.42493513 -0.6799935  -3.3333948  -0.24918023\n",
      " -2.0567842  -0.653301   -1.0410166  -0.6527277  -0.6994715  -0.7838443\n",
      " -0.24724625 -0.04899453 -3.7500641  -0.4552429  -3.1248815  -0.8474555\n",
      " -0.80181885 -0.55279994]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting the constant to 50 Neurons in the Hidden layer \\n\\n',model_ANN.layers[0].get_weights()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting X1 to 50 Neurons in the Hidden layer \n",
      "\n",
      " [ 1.0629019   0.4031103   0.18567498  0.02615019 -0.45092735  0.1480433\n",
      "  0.0689627   0.04018501 -1.3265877  -0.05896894 -0.12530719  0.03257891\n",
      " -0.06545558  0.02533201 -0.49647707 -0.07379184 -0.03375246  0.17853203\n",
      " -0.1301197   0.08988244 -0.48713577  0.07457998  0.00201289  0.39559728\n",
      "  0.09291359  0.16538237  1.5644766  -0.12189148  0.03624357 -0.0872807\n",
      " -0.08144294  0.13196163 -0.08285387 -0.4351346  -1.0726532  -0.32361513\n",
      "  1.5841885  -0.1796068  -0.14344007  0.06149485 -0.24550772  0.0229039\n",
      " -0.13169046  1.1220106  -0.06913649 -0.08849214  0.7882814   0.08060846\n",
      "  0.0846245   0.25876078]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting X1 to 50 Neurons in the Hidden layer \\n\\n',model_ANN.layers[0].get_weights()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting X2 to 50 Neurons in the Hidden layer \n",
      "\n",
      " [-0.34228888  0.09298219  0.18190512 -0.264197   -0.19957164 -0.5707091\n",
      "  0.11313219 -0.25409347 -0.99135566 -0.06337199 -0.02405789  0.01229273\n",
      "  0.02346956  0.02869254  0.00822841 -0.12755004 -0.16741018  0.3100341\n",
      "  0.01609723  0.14065272  0.61396587 -1.0948112   0.05652698 -0.16017275\n",
      " -0.8545678   0.6629309   0.94947463  0.3589706  -0.03408298  0.2596591\n",
      " -0.06246385  0.8390301  -0.05035438  0.23954228  0.16878839 -0.4110005\n",
      " -0.09653471 -0.10380635 -0.7644542   0.02039365 -0.35809174 -0.02916177\n",
      " -0.03061401  1.7770591   1.9175528  -0.11558183 -1.2312815   0.2567467\n",
      "  0.08894061 -0.1309089 ]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting X2 to 50 Neurons in the Hidden layer \\n\\n',model_ANN.layers[0].get_weights()[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting X3 to 50 Neurons in the Hidden layer \n",
      "\n",
      " [ 1.0629019   0.4031103   0.18567498  0.02615019 -0.45092735  0.1480433\n",
      "  0.0689627   0.04018501 -1.3265877  -0.05896894 -0.12530719  0.03257891\n",
      " -0.06545558  0.02533201 -0.49647707 -0.07379184 -0.03375246  0.17853203\n",
      " -0.1301197   0.08988244 -0.48713577  0.07457998  0.00201289  0.39559728\n",
      "  0.09291359  0.16538237  1.5644766  -0.12189148  0.03624357 -0.0872807\n",
      " -0.08144294  0.13196163 -0.08285387 -0.4351346  -1.0726532  -0.32361513\n",
      "  1.5841885  -0.1796068  -0.14344007  0.06149485 -0.24550772  0.0229039\n",
      " -0.13169046  1.1220106  -0.06913649 -0.08849214  0.7882814   0.08060846\n",
      "  0.0846245   0.25876078]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting X3 to 50 Neurons in the Hidden layer \\n\\n',model_ANN.layers[0].get_weights()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting the 50 Neurons in the Hidden layer to the Output layer\n",
      "\n",
      " [[ 1.4893034e+00]\n",
      " [ 3.6677122e-01]\n",
      " [-1.8023610e-01]\n",
      " [-5.4392588e-01]\n",
      " [-4.1866153e-01]\n",
      " [-3.5527134e-01]\n",
      " [-1.1082695e-01]\n",
      " [-1.9311672e-03]\n",
      " [-2.3347626e+00]\n",
      " [ 2.9507071e-01]\n",
      " [-3.4468141e-01]\n",
      " [ 2.9016702e-02]\n",
      " [-7.8461073e-02]\n",
      " [ 5.6380147e-01]\n",
      " [-3.9490297e-01]\n",
      " [-2.1339189e-01]\n",
      " [ 1.4820214e-01]\n",
      " [ 1.1197652e+00]\n",
      " [-4.6786478e-01]\n",
      " [ 1.2909833e+00]\n",
      " [-1.0563377e+00]\n",
      " [-1.6500965e+00]\n",
      " [-1.4146750e-01]\n",
      " [-1.7362884e+00]\n",
      " [-7.1050870e-01]\n",
      " [-6.0508853e-01]\n",
      " [-3.0551949e+00]\n",
      " [ 3.2554307e+00]\n",
      " [ 4.7634903e-01]\n",
      " [-2.0357682e-01]\n",
      " [-3.8442807e-03]\n",
      " [ 5.2709621e-01]\n",
      " [-1.5534474e-01]\n",
      " [-4.0113056e-01]\n",
      " [-3.7866607e+00]\n",
      " [ 2.4336523e-01]\n",
      " [-1.5229518e+00]\n",
      " [ 2.2592391e-01]\n",
      " [-6.3971126e-01]\n",
      " [ 3.0049849e-01]\n",
      " [-3.7297717e-01]\n",
      " [-8.6165778e-03]\n",
      " [-3.7701946e-01]\n",
      " [-1.5372473e+00]\n",
      " [-3.3297932e+00]\n",
      " [ 1.4488806e-01]\n",
      " [-2.7415440e+00]\n",
      " [ 1.0094199e+00]\n",
      " [ 1.6524065e-02]\n",
      " [ 2.1620123e-01]]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting the 50 Neurons in the Hidden layer to the Output layer\\n\\n',model_ANN.layers[1].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE ANN: 0.9770908109789682\n",
      "MSE OLS: 2.0428623165804765\n"
     ]
    }
   ],
   "source": [
    "# Evaluation: Mean squared error ist bei NN double so gut wie Mean Squared Error in OLS ! \n",
    "# Grund: ich habe nicht lineare Transformation in Hidden-Layer-Neuron verwendet!\n",
    "\n",
    "y_pred_ANN=model_ANN.predict(X)\n",
    "print(\"MSE ANN:\", mean_squared_error(np.ravel(y), np.ravel(y_pred_ANN )))\n",
    "print(\"MSE OLS:\", mean_squared_error(np.ravel(y), np.ravel(y_pred_OLS )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Fit Plot Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.86412286072964, 3.401802646419812)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.ravel(y),np.ravel(y_pred_ANN), 'bo')\n",
    "plt.xlim((min(y)-1,max(y)+1))\n",
    "plt.ylim((min(y)-1,max(y)+1))\n",
    "\n",
    "# auf x-Axe ist echte y\n",
    "# auf y-Axe ist geschätzte y -> y hat\n",
    "# perfektes Modell muss eine Linie in der Mittelhalb ergeben -> bei NN schaut hier relativ ok "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Fit Plot OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.86412286072964, 3.401802646419812)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.ravel(y),np.ravel(y_pred_OLS), 'bo')\n",
    "plt.xlim((min(y)-1,max(y)+1))\n",
    "plt.ylim((min(y)-1,max(y)+1))\n",
    "\n",
    "# auf x-Axe ist echte y\n",
    "# auf y-Axe ist geschätzte y -> y hat\n",
    "# perfektes Modell muss eine Linie in der Mittelhalb ergeben -> bei OLS schaut hier nicht sehr gut aus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
