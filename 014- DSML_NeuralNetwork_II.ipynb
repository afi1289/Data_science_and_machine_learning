{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of some data\n",
    "np.random.seed (245)\n",
    "nobs =1000\n",
    "x1= np.random.normal(size=nobs ,scale=1) # ich definiere normal verteilte x1 \n",
    "x2= np.random.normal(size=nobs ,scale=1) # auch x2 ist normalverteilt\n",
    "x3= np.random.normal(size=nobs ,scale=1) # auch x3 ist normalverteilt\n",
    "X= np.c_[np.ones((nobs ,1)),x1,x2,x3] # dann mache ich aus x1,x2, x3 ein Matrix X\n",
    "\n",
    "\n",
    "y= -1.5 + -0.5*x1**2 -0.5*x2**2 +0.25*x3**2 + np.random.normal(size=nobs , scale=1) # fehler ist normalverteilt-> y auch ist normalverteilt\n",
    "\n",
    "\n",
    "\n",
    "OLS=sm.OLS(y,X).fit()\n",
    "y_pred_OLS=OLS.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.23276742,  2.21909962, -1.00408117],\n",
       "       [ 1.        ,  0.81853041,  0.51334014,  0.86191678],\n",
       "       [ 1.        , -0.97334932, -3.00031139,  0.86598633],\n",
       "       ...,\n",
       "       [ 1.        ,  1.62168608, -0.91076001, -0.60039352],\n",
       "       [ 1.        , -0.18710805,  0.74539444, -0.31463947],\n",
       "       [ 1.        , -1.39579166, -1.03862314,  0.32594296]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.14038861, -1.56918942, -5.63452662, -1.37463074, -1.13933778])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,  14.,  34., 100., 212., 281., 256.,  81.,  15.,   4.]),\n",
       " array([-7.86412286, -6.83753031, -5.81093776, -4.78434521, -3.75775266,\n",
       "        -2.73116011, -1.70456756, -0.67797501,  0.34861754,  1.3752101 ,\n",
       "         2.40180265]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y) # y auch normalverteilt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.208\n",
      "Date:                Thu, 06 Feb 2020   Prob (F-statistic):              0.306\n",
      "Time:                        13:18:15   Log-Likelihood:                -1776.1\n",
      "No. Observations:                1000   AIC:                             3560.\n",
      "Df Residuals:                     996   BIC:                             3580.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.3196      0.045    -51.122      0.000      -2.409      -2.231\n",
      "x1             0.0403      0.044      0.923      0.356      -0.045       0.126\n",
      "x2            -0.0181      0.045     -0.404      0.687      -0.106       0.070\n",
      "x3             0.0728      0.046      1.600      0.110      -0.016       0.162\n",
      "==============================================================================\n",
      "Omnibus:                       30.791   Durbin-Watson:                   2.082\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.067\n",
      "Skew:                          -0.380   Prob(JB):                     2.43e-08\n",
      "Kurtosis:                       3.513   Cond. No.                         1.09\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learningrate\n",
    "LR=0.05\n",
    "\n",
    "\n",
    "# Number of neurons\n",
    "Neuron_Out=1\n",
    "Neuron_Hidden=50 # New!\n",
    "\n",
    "#The Activation function -> لسا الوضع لينيار وماني مستخدم شي جديد\n",
    "Activate='linear'\n",
    "\n",
    "\n",
    "#The Optimizer\n",
    "Optimizer= SGD(lr=LR)\n",
    "\n",
    "\n",
    "# The loss function\n",
    "loss='mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 50        \n",
      "=================================================================\n",
      "Total params: 250\n",
      "Trainable params: 250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Neural Network\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed (245)\n",
    "\n",
    "#Initialize the ANN\n",
    "model_ANN= Sequential()\n",
    "\n",
    "# Hidden Lyern -> hier wird Hidden Layer definiert-> Anzahl der Neuronen hier sind 50\n",
    "model_ANN.add(Dense(Neuron_Hidden, activation=Activate, input_shape=(4,), use_bias=False))\n",
    "\n",
    "#Output Layer -> hier wird Output-Layer defniniert\n",
    "model_ANN.add(Dense(Neuron_Out, activation=Activate,use_bias=False))\n",
    "model_ANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200 Parameter/Gewichte in Hidden-Layer -> von jedem x/Input-Neuron zu jedem Hidden-Layer-Neuron habe ich ein Verbindung!\n",
    "# 50 Parameter/Gewichte in Output-Layer -> von jedem Hidden-Layer-Neuron zu einer Output-Neuron\n",
    "\n",
    "# je mehr Parameter desto mehr sollte ich schätzen-> desto komplexer wird für mein Optimierer dieses Modell zu schätzen->aber ich wird flexibler-> aber flexibilität führt zu Overfitting!\n",
    "# also je mehr Gewichte ich habe, desto großer ist das Gefahr von Overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ANN.compile(optimizer=Optimizer , loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.4098\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.1589\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.1738\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1936\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.1201\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1360\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1687\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.1202\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1033\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1084\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0952\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.1345\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1379\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1381\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1565\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.1036\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 2.1156\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1074\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 2.0865\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.1298\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.1192\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 2.1045\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 2.1081\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.1367\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 2.1216\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 2.1088\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 2.1290\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.0905\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.1334\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.1353\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.1332\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 2.1164\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 2.1112\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 2.1125\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 2.0913\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 2.0908\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 2.1121\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 2.1329\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.1101\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 2.0935\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.1135\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1237\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.1097\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 2.1057\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 2.1390\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 2.1113\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 2.1127\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 2.0977\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 2.1242\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 2.0994\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 2.1019\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.0897\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 2.1192\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1476\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1116\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1048\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1154\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 2.0810\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 2.0748\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 2.1380\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 2.0854\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 2.0954\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1339\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1495\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0849\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1058\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0961\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0797\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 2.1103\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 2.1081\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 2.1064\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 2.1136\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.0817\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1064\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0823\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1115\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1160\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1170\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0929\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.1163\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 2.1193\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 2.0876\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 0s 99us/step - loss: 2.1029\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 2.0824\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 2.1237\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1130\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0694\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1029\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1048\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1021\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1063\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1023\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.0669\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1200\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.0947\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.1148\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.1195\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0884\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0795\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.0895\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1094\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.0870\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.0974\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1080\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1167\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1073\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0999\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1136\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0893\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0567\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.0926\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0781\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1057\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1042\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0883\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0948\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1080\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.1139\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0827\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.1162\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 2.1118\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 2.1283\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1164\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0731\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1059\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1029\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1013\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0918\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1344\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1055\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0864\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0735\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.1299\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1021\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1278\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.1370\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1309\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.1082\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0723\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1177\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1010\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0859\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.0981\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0902\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1057\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.0996\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1112\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0810\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1302\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1138\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1013\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0935\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0805\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0748\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1202\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0883\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1017\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.1143\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0797\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0919\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0928\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1274\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1099\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0850\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0852\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1019\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0851\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1089\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0942\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1314\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1019\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0991\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0832\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1072\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1079\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 2.0848\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 2.1325\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 2.1018\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 0s 101us/step - loss: 2.0934\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 2.1355\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 2.0940\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.0992\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.1030\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.0874\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1079\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0992\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.1044\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0954\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1454\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0979\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1197\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.0914\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0775\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0986\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.1144\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.0995\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.0893\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.0853\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 2.1433\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 2.0946\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 2.1132\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.1608\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1057\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0857\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0893\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0871\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1195\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.1200\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0619\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1132\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1416\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1020\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0859\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 2.0918\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1131\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.0977\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1035\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1007\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0988\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0960\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1169\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1050\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0885\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1137\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1340\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1123\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1158\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 2.0920\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1272\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 2.0905\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 2.0909\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.0825\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1077\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1142\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1010\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1093\n",
      "Epoch 237/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0842\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1115\n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1080\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1243\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.0903\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0814\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0927\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.0996\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.0936\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.1224\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 2.0859\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0808\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1139\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1024\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0733\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1172\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1127\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1328\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1155\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1121\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1002\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0890\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1287\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1230\n",
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1530\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1068\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0983\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0738\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0826\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1302\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1066\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1013\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0969\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1108\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1140\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0784\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0939\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1082\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0980\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1263\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0893\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0868\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0858\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0939\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0936\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1215\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0896\n",
      "Epoch 284/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1152\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0921\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0792\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0976\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0883\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 2.1106\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 2.1065\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 2.0923\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 2.1094\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 2.0860\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 2.1153\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.0996\n",
      "Epoch 296/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 2.1054\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1123\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0997\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0935\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0986\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1058\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1038\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0865\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.0957\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 2.1206\n",
      "Epoch 306/500\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 2.1279\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 2.1029\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 2.1098\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.1110\n",
      "Epoch 310/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1123\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 2.1408\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1156\n",
      "Epoch 313/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0983\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1070\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.0973\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1039\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0840\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0808\n",
      "Epoch 319/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1324\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.1408\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 2.0965\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 2.1027\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 2.0984\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 2.1140\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 2.0739\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 2.1115\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.0918\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1027\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1005\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.0810\n",
      "Epoch 331/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1209\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1411\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1235\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.0942\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1111\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0988\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.0979\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 2.0919\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 2.0894\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 2.0764\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.0959\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1082\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1510\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1182\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1050\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0890\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.0955\n",
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1196\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0755\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0988\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1146\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.0898\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.0818\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.0961\n",
      "Epoch 355/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.1155\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1118\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0898\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 2.0974\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 2.1031\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 2.1020\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 2.1052\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.1204\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1064\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1138\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.0931\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1104\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1187\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1185\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1157\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.0826\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 2.0944\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.0792\n",
      "Epoch 373/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 64us/step - loss: 2.1203\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.1061\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.0883\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.0818\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.0989\n",
      "Epoch 378/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 2.1261\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.0900\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0936\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0880\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1188\n",
      "Epoch 383/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1108\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0997\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 2.1074\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0970\n",
      "Epoch 387/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0933\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1167\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1038\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1151\n",
      "Epoch 391/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1005\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0968\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0797\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1003\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.1029\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1029\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0850\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0783\n",
      "Epoch 399/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1298\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1004\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.0962\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1319\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1210\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1072\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1005\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1390\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0993\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0872\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0857\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.0795\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1132\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1165\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0939\n",
      "Epoch 414/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1145\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0786\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0966\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.0998\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1218\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0966\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1401\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1050\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1036\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0974\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0990\n",
      "Epoch 425/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1045\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.1162\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0847\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0961\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0966\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1311\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1019\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1170\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0771\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0837\n",
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1048\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1059\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.0780\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1053\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1096\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.1127\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.0967\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1031\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0959\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0925\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0991\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0893\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0834\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0935\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1067\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.1097\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.0955\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1061\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 2.1041\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.0842\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.1086\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 2.1080\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.1327\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.0995\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1133\n",
      "Epoch 460/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1077\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0711\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 2.1041\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1229\n",
      "Epoch 464/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.1026\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0868\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0979\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.0783\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0812\n",
      "Epoch 469/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1021\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 2.0947\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1050\n",
      "Epoch 472/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0945\n",
      "Epoch 473/500\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.1061\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1286\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1311\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0913\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1293\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0870\n",
      "Epoch 479/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0974\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0944\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1222\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.1784\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.0845\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0998\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.0869\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1364\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.0944\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.0984\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.0904\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.1007\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0926\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0825\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 2.0950\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.1040\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1105\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 2.0869\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 2.0930\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 2.1176\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0913\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.0738\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "history_ANN=model_ANN.fit(\n",
    "X, # training data\n",
    "y, # training targets\n",
    "epochs=500,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_ANN.history['loss'])\n",
    "#plt.plot(history_ANN.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting the constant to 50 Neurons in the Hidden layer \n",
      "\n",
      " [ 0.10780312  0.17237863 -0.09808438  0.5631953  -0.01460823 -0.55059725\n",
      "  0.3342203  -0.05902416  0.12056092 -0.14392516  0.59019125  0.40899682\n",
      " -0.19639093 -0.32453176 -0.21745841  0.30552143 -0.16954453 -0.43999842\n",
      "  0.53984505 -0.4855369  -0.08452999 -0.01204138 -0.0790252   0.3284002\n",
      " -0.03498581  0.01474908 -0.30875486 -0.47183597 -0.4807888  -0.3124229\n",
      "  0.31249616  0.20423101  0.22296396 -0.00349152  0.16550757 -0.1933137\n",
      " -0.17515203 -0.13692336 -0.36310893 -0.13755311  0.08860493 -0.61538863\n",
      "  0.61626107 -0.4623279  -0.12905143  0.28714135 -0.0141036  -0.29997152\n",
      " -0.47936907 -0.28458828]\n"
     ]
    }
   ],
   "source": [
    "# constant to 50 weights اسع صراحة ما اعرف ليش بي اوزان هون بس على ما اعتقد انه اعتبره اكس صفر\n",
    "print('Weights connecting the constant to 50 Neurons in the Hidden layer \\n\\n',model_ANN.layers[0].get_weights()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting X1 to 50 Neurons in the Hidden layer \n",
      "\n",
      " [ 0.00330912  0.00526298 -0.00298354  0.01713682 -0.00046795 -0.01670622\n",
      "  0.01016697 -0.00177272  0.00366362 -0.00438308  0.01794887  0.01244491\n",
      " -0.0059621  -0.00986199 -0.00661367  0.00928996 -0.00514982 -0.01335375\n",
      "  0.01638457 -0.01475579 -0.00260334 -0.0003561  -0.00241495  0.01000733\n",
      " -0.00104932  0.00044884 -0.00937922 -0.01433839 -0.01461548 -0.00951863\n",
      "  0.00949868  0.00620357  0.00676924 -0.00012644  0.00499764 -0.00589307\n",
      " -0.00532174 -0.00416998 -0.01102174 -0.00418214  0.00268739 -0.01871984\n",
      "  0.01873489 -0.01405787 -0.00391267  0.00873546 -0.00041502 -0.00915779\n",
      " -0.01456946 -0.0086231 ]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting X1 to 50 Neurons in the Hidden layer \\n\\n',model_ANN.layers[0].get_weights()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting X2 to 50 Neurons in the Hidden layer \n",
      "\n",
      " [ 5.20216243e-04  8.50021548e-04 -4.79360373e-04  2.87967175e-03\n",
      " -3.70229500e-05 -2.84979912e-03  1.69954228e-03 -3.39288381e-04\n",
      "  6.13583950e-04 -7.38595263e-04  3.00738495e-03  2.06576078e-03\n",
      " -1.02611911e-03 -1.67427398e-03 -1.13013410e-03  1.56091468e-03\n",
      " -8.79420666e-04 -2.27207807e-03  2.79395562e-03 -2.49038800e-03\n",
      " -3.94430535e-04 -7.74345244e-05 -3.76822194e-04  1.63995533e-03\n",
      " -1.80443036e-04  8.20917703e-05 -1.56523241e-03 -2.40005110e-03\n",
      " -2.46144412e-03 -1.57422433e-03  1.58518972e-03  1.04623428e-03\n",
      "  1.15086883e-03 -1.36400795e-05  8.86314316e-04 -9.77880554e-04\n",
      " -8.84596724e-04 -7.16112554e-04 -1.89309893e-03 -7.07058469e-04\n",
      "  4.66750003e-04 -3.13057750e-03  3.14633199e-03 -2.33527482e-03\n",
      " -6.56468037e-04  1.43537868e-03 -9.68872773e-05 -1.48664031e-03\n",
      " -2.45382148e-03 -1.47549214e-03]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting X2 to 50 Neurons in the Hidden layer \\n\\n',model_ANN.layers[0].get_weights()[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting X3 to 50 Neurons in the Hidden layer \n",
      "\n",
      " [ 0.00330912  0.00526298 -0.00298354  0.01713682 -0.00046795 -0.01670622\n",
      "  0.01016697 -0.00177272  0.00366362 -0.00438308  0.01794887  0.01244491\n",
      " -0.0059621  -0.00986199 -0.00661367  0.00928996 -0.00514982 -0.01335375\n",
      "  0.01638457 -0.01475579 -0.00260334 -0.0003561  -0.00241495  0.01000733\n",
      " -0.00104932  0.00044884 -0.00937922 -0.01433839 -0.01461548 -0.00951863\n",
      "  0.00949868  0.00620357  0.00676924 -0.00012644  0.00499764 -0.00589307\n",
      " -0.00532174 -0.00416998 -0.01102174 -0.00418214  0.00268739 -0.01871984\n",
      "  0.01873489 -0.01405787 -0.00391267  0.00873546 -0.00041502 -0.00915779\n",
      " -0.01456946 -0.0086231 ]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting X3 to 50 Neurons in the Hidden layer \\n\\n',model_ANN.layers[0].get_weights()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting the 50 Neurons in the Hidden layer to the Output layer\n",
      "\n",
      " [[-0.04385008]\n",
      " [-0.07870575]\n",
      " [ 0.05027489]\n",
      " [-0.26310757]\n",
      " [ 0.00808061]\n",
      " [ 0.2607215 ]\n",
      " [-0.16032158]\n",
      " [ 0.02395622]\n",
      " [-0.06069269]\n",
      " [ 0.0732206 ]\n",
      " [-0.2826032 ]\n",
      " [-0.19719723]\n",
      " [ 0.08530917]\n",
      " [ 0.14965121]\n",
      " [ 0.09763848]\n",
      " [-0.14345676]\n",
      " [ 0.08257897]\n",
      " [ 0.2116947 ]\n",
      " [-0.25770804]\n",
      " [ 0.23310295]\n",
      " [ 0.03846983]\n",
      " [ 0.00098558]\n",
      " [ 0.03822497]\n",
      " [-0.15884042]\n",
      " [ 0.01633594]\n",
      " [-0.00790868]\n",
      " [ 0.1448694 ]\n",
      " [ 0.23039454]\n",
      " [ 0.23191226]\n",
      " [ 0.14860241]\n",
      " [-0.14710839]\n",
      " [-0.09208874]\n",
      " [-0.10086777]\n",
      " [-0.0013786 ]\n",
      " [-0.08391085]\n",
      " [ 0.09647486]\n",
      " [ 0.07743942]\n",
      " [ 0.06296962]\n",
      " [ 0.16529366]\n",
      " [ 0.06659525]\n",
      " [-0.04419359]\n",
      " [ 0.29384282]\n",
      " [-0.29325542]\n",
      " [ 0.22078553]\n",
      " [ 0.06075438]\n",
      " [-0.13826182]\n",
      " [-0.00131266]\n",
      " [ 0.14871062]\n",
      " [ 0.22400396]\n",
      " [ 0.13924284]]\n"
     ]
    }
   ],
   "source": [
    "print('Weights connecting the 50 Neurons in the Hidden layer to the Output layer\\n\\n',model_ANN.layers[1].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE ANN: 2.065602762885204\n",
      "MSE OLS: 2.0428623165804765\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the fit\n",
    "y_pred_ANN=model_ANN.predict(X)\n",
    "print(\"MSE ANN:\", mean_squared_error(np.ravel(y), np.ravel(y_pred_ANN ))) \n",
    "print(\"MSE OLS:\", mean_squared_error(np.ravel(y), np.ravel(y_pred_OLS )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean sequared error in NN ist schlechter als Mean sequared error in OLS, obwohl ich mein Modell in NN komplexer gemacht habe!\n",
    "### was ist der Grund dazu? -> ich habe Modell je komplexer gemacht aber die Verbindung zwischen Input x und Output y ist  noch Linear! weil Aktivierungsfunktion in Hidden-Layer-Neurons 'linear' ist! \n",
    "\n",
    "# Sehe Beispiel auf Papier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
